{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "108a23fd-318b-4321-800e-137e50b66f69",
   "metadata": {},
   "source": [
    "#Imports\n",
    "import math\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "import re"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "92a2c59c-7227-4602-9179-b4a2cf949cd1",
   "metadata": {},
   "source": [
    "## Funcion para limpiar strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f72860-9939-4e29-9519-ae3e0ac4ea9e",
   "metadata": {},
   "source": [
    "def limpiar(texto):\n",
    "    return re.sub(r'[^A-Za-z0-9]', '', texto)\n",
    "def limpiarDbpedia(texto):\n",
    "    return texto.replace(\"http://dbpedia.org/resource/\", \"\").replace(\"_\", \" \")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "874cdf49-f8e7-45df-bc56-b655b6e90976",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a71d9716-34e8-4987-a25b-ac3249fc990a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data = pd.read_csv(\"ScopusSearch.csv\")\n",
    "data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75f214ca-924d-45cf-a34c-cdc3dca394c7",
   "metadata": {},
   "source": [
    "data['coverDate'] = pd.to_datetime(data['coverDate'], format='%Y-%m-%d')\n",
    "data['año'] = data['coverDate'].dt.year\n",
    "len(data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97521596-e206-424b-80ac-760b5b150b09",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Obtener el conteo de filas por año\n",
    "conteo_por_año = data['año'].value_counts().sort_index()\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "conteo_por_año.plot(kind='bar', color='skyblue')\n",
    "\n",
    "# Agregar los valores al final de cada barra de manera horizontal\n",
    "for p in plt.gca().patches:\n",
    "    height = p.get_height()\n",
    "    plt.text(p.get_x() + p.get_width() / 2, height + 0.05 * height,  # Posición del texto\n",
    "             int(height),  # El valor que se mostrará\n",
    "             ha='center',  # Alinear horizontalmente al centro\n",
    "             va='bottom')  # Alinear verticalmente al final\n",
    "\n",
    "plt.title('Publicaciones por año')\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f29bb5c-eb97-456e-89fb-acae070638c6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "data1 = pd.read_csv(\"AbstractRetrieval.csv\")\n",
    "data1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbe8d83b-190d-48f8-8690-9a03aac9e003",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "scimagojr = pd.read_csv(\"123.csv\")\n",
    "journalOriginal = data[[\"eid\",\"source_id\"]]\n",
    "merged_journal = pd.merge(journalOriginal, scimagojr, how='left', left_on='source_id', right_on='Sourceid')\n",
    "merged_journal = merged_journal[[\"eid\",\"source_id\",\"Publisher\",\"Issn\",\"Rank\",\"Title\",\"SJR\",\n",
    "                                 \"H index\",\"Coverage\",\"SJR Best Quartile\",\"Categories\",\"Region\",\"Country\"]]\n",
    "merged_journal"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de0f7b3f-1c4c-4b59-828b-d95df4aa091b",
   "metadata": {},
   "source": [
    "mergeData = pd.merge(data, data1, on='eid', how='left')\n",
    "mergeData"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8acb7867-0738-4878-85b2-2571c6f66b6a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "referen = pd.read_csv(\"references.csv\")\n",
    "referen = pd.merge(data['eid'], referen, on='eid', how='right')\n",
    "referen"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec95db6b-462c-456b-9d2a-6f089011f133",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "journ = merged_journal.fillna(0)\n",
    "journ.rename(columns={'H index': 'hIndex'}, inplace=True)\n",
    "journ.rename(columns={'SJR Best Quartile': 'SJRBestQuartile'}, inplace=True)\n",
    "journ.head(2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e267b778-7027-4780-9605-93c7e584ec53",
   "metadata": {},
   "source": [
    "triplesLLm = pd.read_csv(\"triplesLLMcompletas.csv\")\n",
    "triplesLLm.rename(columns={'tail': 'tail1'}, inplace=True)\n",
    "triplesLLm = triplesLLm.dropna(subset=['tail1'])\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2fd41594-36ef-4f53-b8f0-74ce9496f89d",
   "metadata": {},
   "source": [
    "## Creacion de csv para NEO4J\n",
    "## Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cec9e39-6154-4ce9-95a5-373e04b66c4a",
   "metadata": {},
   "source": [
    "papers = mergeData[[\"eid\",\"doi\",\"title\",\"subtypeDescription\",\"citedby_count\",\"url\",\"description\"]]\n",
    "papers.columns = ['identifier', 'doi', 'title', 'publicationType', 'citation', 'url',\"description\"]\n",
    "papers.to_csv('csvNEO4J/Nodos/papers.csv', index=False)\n",
    "papers"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5b9e798e-508f-4194-b5d1-3c5b9c6d0f8b",
   "metadata": {},
   "source": [
    "## KeyWords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8bd5c4-09b5-4bcf-bb87-302a805b4ea2",
   "metadata": {},
   "source": [
    "## Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b03be065-87d9-4ba3-a573-d9812a50a65f",
   "metadata": {},
   "source": [
    "keyWords = mergeData[[\"eid\",\"authkeywords\",\"idxterms\"]]\n",
    "keyWords = keyWords.fillna(0)\n",
    "paperKey = []\n",
    "Key = []\n",
    "for c in keyWords.itertuples():\n",
    "    if c.authkeywords != 0:\n",
    "        h = c.authkeywords.split(' | ')\n",
    "        for i in h:\n",
    "            paperKey.append([c.eid,limpiar(i)]) \n",
    "            Key.append([limpiar(i),i,\"authorKeywords\"])\n",
    "    \n",
    "    if c.idxterms != 0:\n",
    "        paperKey.append([c.eid,limpiar(c.idxterms[2:-2])])\n",
    "        Key.append([limpiar(c.idxterms[2:-2]),c.idxterms[2:-2],\"idxterms\"])\n",
    "        \n",
    "        \n",
    "paperKey = pd.DataFrame(paperKey, columns=['papers', 'key']).drop_duplicates()\n",
    "paperKey.to_csv('csvNEO4J/Relaciones/papers-key.csv', index=False)\n",
    "           \n",
    "Key = pd.DataFrame(Key, columns=['identifier', 'name','contentType']).drop_duplicates()\n",
    "Key.to_csv('csvNEO4J/Nodos/key.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a74a6a0b-3b8b-4cb5-a978-621eb9d6de36",
   "metadata": {},
   "source": [
    "keyWords1 = keyWords[keyWords['idxterms'] != 0]\n",
    "keyWords1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6d606cd9-1659-46f1-b465-64f8329a60d9",
   "metadata": {},
   "source": [
    "paperPublisher = []\n",
    "publisher1 = []\n",
    "publisher = mergeData[[\"eid\",\"publisher\"]].fillna(0)\n",
    "for c in publisher.itertuples():\n",
    "    if c.publisher != 0:\n",
    "        paperPublisher.append([c.eid,limpiar(c.publisher)])\n",
    "        publisher1.append([limpiar(c.publisher),c.publisher])\n",
    "        \n",
    "paperPublisher1 = pd.DataFrame(paperPublisher, columns=['paper', 'publisher']).drop_duplicates()\n",
    "paperPublisher1.to_csv('csvNEO4J/Relaciones/paperPublisher.csv', index=False)\n",
    "\n",
    "publisher2 = pd.DataFrame(publisher1, columns=['identifier', 'name']).drop_duplicates()\n",
    "publisher2.to_csv('csvNEO4J/Nodos/publisher.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0cb5d127-8267-4489-9fe7-20d7d16f7c31",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b29ef08-fdc1-4561-a343-c2db06f420b3",
   "metadata": {},
   "source": [
    "ref = []\n",
    "paper2 = []\n",
    "referen1 = referen.dropna(subset=[ 'title'])\n",
    "\n",
    "for c in referen1.itertuples():\n",
    "    ref.append([c.eid,\"2-s2.0-\"+str(c.id)])\n",
    "    paper2.append([\"2-s2.0-\"+str(c.id),c.doi,c.title])\n",
    "    \n",
    "\n",
    "ref = pd.DataFrame(ref, columns=['paper1', 'paper2']).drop_duplicates()\n",
    "ref.to_csv('csvNEO4J/Relaciones/references.csv', index=False)    \n",
    "\n",
    "\n",
    "# Asegúrate de que ambos DataFrames tengan la columna 'identificador'\n",
    "\n",
    "paper2 = pd.DataFrame(paper2, columns=['identifier','doi','title']).drop_duplicates(subset=['identifier'])\n",
    "paper2 = paper2[~paper2['identifier'].isin(papers['identifier'])]\n",
    "paper2.to_csv('csvNEO4J/Nodos/papers2.csv', index=False) \n",
    "paper2\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8197a81e-2fe9-4abe-9eca-c52c6d5f252c",
   "metadata": {},
   "source": [
    "## Journal / Country / Region / Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "58c11115-01d0-480f-b135-6559b0a11a3c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "paperJournal = []\n",
    "journal = []\n",
    "journalPublisher = []\n",
    "journalCountry = []\n",
    "country = []\n",
    "regionCountry = []\n",
    "region = []\n",
    "journalConcept = []\n",
    "Concept = []\n",
    "for c in journ.itertuples():\n",
    "    if c.Publisher != 0:       \n",
    "        paperJournal.append([c.eid,c.source_id])\n",
    "        \n",
    "        journal.append([c.source_id,c.Issn,c.Rank,c.Title,c.SJR,c.hIndex,c.Coverage,c.SJRBestQuartile])\n",
    "        \n",
    "        journalPublisher.append([c.source_id,limpiar(c.Publisher)])\n",
    "        \n",
    "        journalCountry.append([c.source_id,limpiar(c.Country)])\n",
    "        \n",
    "        country.append([limpiar(c.Country),c.Country])\n",
    "        \n",
    "        regionCountry.append([limpiar(c.Region),limpiar(c.Country)])\n",
    "        \n",
    "        region.append([limpiar(c.Region),c.Region])\n",
    "\n",
    "        g = c.Categories.split(', ')\n",
    "\n",
    "        for i in g:\n",
    "            journalConcept.append([c.source_id,limpiar(i.split(' (')[0])])\n",
    "            Concept.append([limpiar(i.split(' (')[0]),i.split(' (')[0]])\n",
    "        \n",
    "paperJournal = pd.DataFrame(paperJournal, columns=['paper', 'journal']).drop_duplicates()\n",
    "paperJournal.to_csv('csvNEO4J/Relaciones/paperJournal.csv', index=False)    \n",
    "\n",
    "journal = pd.DataFrame(journal, columns=['identifier', 'issn','rank','title','sjr','hIndex','coverage','bestQuartile']).drop_duplicates()\n",
    "journal.to_csv('csvNEO4J/Nodos/Journal.csv', index=False)    \n",
    "\n",
    "journalPublisher = pd.DataFrame(journalPublisher, columns=['journal', 'publisher']).drop_duplicates()\n",
    "journalPublisher.to_csv('csvNEO4J/Relaciones/journalPublisher.csv', index=False)   \n",
    "\n",
    "journalCountry = pd.DataFrame(journalCountry, columns=['journal', 'country']).drop_duplicates()\n",
    "journalCountry.to_csv('csvNEO4J/Relaciones/journalCountry.csv', index=False)   \n",
    "\n",
    "# Se añaden en la parte de affiliation, para crear un solo archivo\n",
    "# country = pd.DataFrame(country, columns=['identifier', 'name']).drop_duplicates()\n",
    "# country.to_csv('csvNEO4J/country.csv', index=False)   \n",
    "\n",
    "regionCountry = pd.DataFrame(regionCountry, columns=['region', 'country']).drop_duplicates()\n",
    "regionCountry.to_csv('csvNEO4J/Relaciones/regionCountry.csv', index=False)   \n",
    "\n",
    "region = pd.DataFrame(region, columns=['identifier', 'name']).drop_duplicates()\n",
    "region.to_csv('csvNEO4J/Nodos/region.csv', index=False) \n",
    "\n",
    "journalConcept = pd.DataFrame(journalConcept, columns=['journal', 'concept']).drop_duplicates()\n",
    "journalConcept.to_csv('csvNEO4J/Relaciones/journalConcept.csv', index=False) \n",
    "\n",
    "Concept = pd.DataFrame(Concept, columns=['identifier', 'name']).drop_duplicates()\n",
    "Concept.to_csv('csvNEO4J/Nodos/Concept.csv', index=False) \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f87e0f61-8bd1-4808-8e5c-7ebe1e9a6956",
   "metadata": {},
   "source": [
    "## Autor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e0974777-69f7-4af7-a4ae-52b82ad6e2f6",
   "metadata": {},
   "source": [
    "dataAu = data.fillna(0)\n",
    "\n",
    "papersAutores = []\n",
    "autores = []\n",
    "\n",
    "autoresAff = []\n",
    "\n",
    "for c in dataAu.itertuples():\n",
    "\n",
    "    auID = c.author_ids.split(';')\n",
    "    auName = c.author_names.split(';')\n",
    "    if c.author_afids != 0:\n",
    "        authorAfids = [afid.strip() for afid in c.author_afids.split(';') if afid.strip()]\n",
    "\n",
    "    \n",
    "    for i in range(len(auID)):\n",
    "        papersAutores.append([c.eid,auID[i]])\n",
    "        autores.append([auID[i],auName[i]])\n",
    "        \n",
    "        if c.author_afids != 0:\n",
    "            aff = authorAfids[0].split('-')\n",
    "            for g in aff:\n",
    "                autoresAff.append([auID[i],g]) \n",
    "                \n",
    "papersAutores = pd.DataFrame(papersAutores, columns=['paper', 'autor']).drop_duplicates()\n",
    "papersAutores.to_csv('csvNEO4J/Relaciones/papersAutores.csv', index=False) \n",
    "\n",
    "autores = pd.DataFrame(autores, columns=['identifier', 'name']).drop_duplicates()\n",
    "autores.to_csv('csvNEO4J/Nodos/autores.csv', index=False) \n",
    "\n",
    "autoresAff = pd.DataFrame(autoresAff, columns=['autor', 'affiliation']).drop_duplicates()\n",
    "autoresAff.to_csv('csvNEO4J/Relaciones/autoresAffiliations.csv', index=False) \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ea4d414b-0288-4ac5-b813-f8ca03482998",
   "metadata": {},
   "source": [
    "## Affiliation/City/Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c87d607-b665-4a17-9d84-e0b50876e27b",
   "metadata": {},
   "source": [
    "aff = []\n",
    "affCity = []\n",
    "city = []\n",
    "cityCountry = []\n",
    "\n",
    "for c in dataAu.itertuples():\n",
    "    if c.afid != 0:\n",
    "        afid = c.afid.split(';')\n",
    "        afidName = c.affilname.split(';')\n",
    "        if c.affiliation_city != 0:\n",
    "            afCity = c.affiliation_city.split(';')\n",
    "            afCountry = c.affiliation_country.split(';')\n",
    "            \n",
    "        for i in range(len(afid)):\n",
    "            aff.append([afid[i],afidName[i]])\n",
    "            if c.affiliation_city != 0:\n",
    "                affCity.append([afid[i],limpiar(afCity[i])])\n",
    "                city.append([limpiar(afCity[i]),afCity[i]])\n",
    "                cityCountry.append([limpiar(afCity[i]),limpiar(afCountry[i])])\n",
    "                country.append([limpiar(afCountry[i]),afCountry[i]])\n",
    "\n",
    "aff = pd.DataFrame(aff, columns=['identifier', 'name']).drop_duplicates()\n",
    "aff.to_csv('csvNEO4J/Nodos/affiliation.csv', index=False) \n",
    "\n",
    "affCity = pd.DataFrame(affCity, columns=['affili', 'city']).drop_duplicates()\n",
    "affCity.replace('', pd.NA, inplace=True)\n",
    "affCity = affCity.dropna()\n",
    "affCity.to_csv('csvNEO4J/Relaciones/affCity.csv', index=False)\n",
    "\n",
    "city = pd.DataFrame(city, columns=['identifier', 'name']).drop_duplicates()\n",
    "city = city[~(city == '').any(axis=1)]\n",
    "city.to_csv('csvNEO4J/Nodos/city.csv', index=False) \n",
    "\n",
    "cityCountry = pd.DataFrame(cityCountry, columns=['city', 'country']).drop_duplicates()\n",
    "cityCountry = cityCountry[~(cityCountry == '').any(axis=1)]\n",
    "cityCountry.to_csv('csvNEO4J/Relaciones/cityCountry.csv', index=False)\n",
    "\n",
    "country = pd.DataFrame(country, columns=['identifier', 'name']).drop_duplicates()\n",
    "country.to_csv('csvNEO4J/Nodos/country.csv', index=False) "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a472da09-61f2-4acb-9763-fdc570ca7678",
   "metadata": {},
   "source": [
    "## Chunks / Fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0c7ca3",
   "metadata": {},
   "source": [
    "paperChunk = []   #\n",
    "Chunk = []        #\n",
    "\n",
    "chunkFact = []    #\n",
    "\n",
    "Fact = []         \n",
    "\n",
    "Algoritm = []\n",
    "FactAlg = []\n",
    "FactAlgT = []\n",
    "\n",
    "DataSet = []\n",
    "FactDat = []\n",
    "FactDatT = []\n",
    "\n",
    "Evaluation = []\n",
    "FactEva = []\n",
    "FactEvaT = []\n",
    "\n",
    "Exprement = []\n",
    "FactExp = []\n",
    "FactExpT = []\n",
    "\n",
    "\n",
    "Group = []\n",
    "FactGro = []\n",
    "FactGroT = []\n",
    "\n",
    "\n",
    "Method = []\n",
    "FactMet = []\n",
    "FactMetT = []\n",
    "\n",
    "\n",
    "Person = []\n",
    "FactPer = []\n",
    "FactPerT = []\n",
    "\n",
    "\n",
    "ResearchField = []\n",
    "FactRes = []\n",
    "FactResT = []\n",
    "\n",
    "Technology = []\n",
    "FactTec = []\n",
    "FactTecT = []\n",
    "\n",
    "\n",
    "Tool = []\n",
    "FactToo = []\n",
    "FactTooT = []"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986b3ba1-7879-4721-a01a-763728cf0cdd",
   "metadata": {},
   "source": [
    "l = len(triplesLLm) -1\n",
    "i = 1\n",
    "j = 1\n",
    "last = 0\n",
    "HI = len(triplesLLm)\n",
    "for idx in range (HI):\n",
    "    c = triplesLLm.iloc[idx]\n",
    "    chunkFact.append([c.eid +\"_chunk\"+str(i),c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j)])\n",
    "    Fact.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),c.head1,c.relation,c.tail1])\n",
    "    if(c.head1.startswith(\"http\")):\n",
    "        match c.head_type:\n",
    "            case \"Algoritm\":\n",
    "                Algoritm.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactAlg.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1),])\n",
    "                \n",
    "            case \"DataSet\":\n",
    "                DataSet.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactDat.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1)])\n",
    "\n",
    "                \n",
    "            case \"Evaluation\":\n",
    "                Evaluation.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactEva.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1)])\n",
    "\n",
    "                \n",
    "            case \"Exprement\":\n",
    "                Exprement.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactExp.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1)])\n",
    "                \n",
    "            case \"Group\":\n",
    "                Group.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactGro.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1)])\n",
    "                \n",
    "            case \"Method\":\n",
    "                Method.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactMet.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1)])\n",
    "                \n",
    "            case \"Person\":\n",
    "                Person.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactPer.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1)])\n",
    "                \n",
    "            case \"ResearchField\":\n",
    "                ResearchField.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactRes.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1)])\n",
    "                \n",
    "            case \"Technology\":\n",
    "                Technology.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactTec.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1)])\n",
    "\n",
    "                \n",
    "            case \"Tool\":\n",
    "                Tool.append([limpiar(c.head1),c.head1,limpiarDbpedia(c.head1)])\n",
    "                FactToo.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.head1)])\n",
    "                \n",
    "                \n",
    "    if(c.tail1.startswith(\"http\")):\n",
    "        match c.tail_type:\n",
    "            case \"Algoritm\":\n",
    "                FactAlgT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "                \n",
    "            case \"DataSet\":\n",
    "                FactDatT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "\n",
    "            case \"Evaluation\":\n",
    "                FactEvaT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "                \n",
    "            case \"Exprement\":\n",
    "                FactExpT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "                \n",
    "            case \"Group\":\n",
    "                FactGroT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "                \n",
    "            case \"Method\":\n",
    "                FactMetT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "                \n",
    "            case \"Person\":\n",
    "                FactPerT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "                \n",
    "            case \"ResearchField\":\n",
    "                FactResT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "                \n",
    "            case \"Technology\":\n",
    "                FactTecT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "    \n",
    "            case \"Tool\":\n",
    "                FactTooT.append([c.eid +\"_chunk\"+str(i)+\"_fact\"+str(j),limpiar(c.tail1)])\n",
    "        \n",
    "    j += 1        \n",
    "    if (idx != l):\n",
    "        cSig = triplesLLm.iloc[idx+1]\n",
    "        if (c.eid == cSig.eid and c.id != cSig.id):\n",
    "            Chunk.append([c.eid +\"_chunk\"+str(i),c.content,c.vector,c.word_count,c.eid +\"_chunk\"+str(i+1)])\n",
    "            paperChunk.append([c.eid,c.eid +\"_chunk\"+str(i)])\n",
    "            i += 1\n",
    "            j = 1\n",
    "\n",
    "        elif (c.id != cSig.id):\n",
    "            Chunk.append([c.eid +\"_chunk\"+str(i),c.content,c.vector,c.word_count])\n",
    "            paperChunk.append([c.eid,c.eid +\"_chunk\"+str(i)])\n",
    "            i = 1\n",
    "\n",
    "    else:\n",
    "        Chunk.append([c.eid +\"_chunk\"+str(i),c.content,c.vector,c.word_count])\n",
    "        paperChunk.append([c.eid,c.eid +\"_chunk\"+str(i)])\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59a2e42a-bc69-4c21-b499-929c93b82379",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "paperChunk = pd.DataFrame(paperChunk, columns=['paper', 'chunk']).drop_duplicates()\n",
    "paperChunk.to_csv('csvNEO4J/Relaciones/paperChunk.csv', index=False)\n",
    "\n",
    "Chunk = pd.DataFrame(Chunk, columns=['identifier', 'content','vector','word_count','next']).drop_duplicates()\n",
    "Chunk.to_csv('csvNEO4J/Nodos/chunk.csv', index=False) \n",
    "\n",
    "chunkFact = pd.DataFrame(chunkFact, columns=['chunk', 'fact']).drop_duplicates()\n",
    "chunkFact.to_csv('csvNEO4J/Relaciones/chunkFact.csv', index=False)\n",
    "\n",
    "Fact = pd.DataFrame(Fact, columns=['identifier', 'hasSubject','hasProperty','hasObject']).drop_duplicates()\n",
    "Fact.to_csv('csvNEO4J/Nodos/fact.csv', index=False) \n",
    "\n",
    "\n",
    "Algoritm = pd.DataFrame(Algoritm, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "Algoritm.to_csv('csvNEO4J/Nodos/algoritm.csv', index=False)   \n",
    "FactAlg = pd.DataFrame(FactAlg, columns=['fact', 'algoritm']).drop_duplicates()\n",
    "FactAlg.to_csv('csvNEO4J/Relaciones/FactAlg.csv', index=False)\n",
    "FactAlgT = pd.DataFrame(FactAlgT, columns=['fact', 'algoritm']).drop_duplicates()\n",
    "FactAlgT.to_csv('csvNEO4J/Relaciones/FactAlgT.csv', index=False)\n",
    "\n",
    "DataSet = pd.DataFrame(DataSet, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "DataSet.to_csv('csvNEO4J/Nodos/dataSet.csv', index=False)   \n",
    "FactDat = pd.DataFrame(FactDat, columns=['fact', 'dataSet']).drop_duplicates()\n",
    "FactDat.to_csv('csvNEO4J/Relaciones/factDat.csv', index=False)\n",
    "FactDatT = pd.DataFrame(FactDatT, columns=['fact', 'dataSet']).drop_duplicates()\n",
    "FactDatT.to_csv('csvNEO4J/Relaciones/factDatT.csv', index=False)\n",
    "\n",
    "Evaluation = pd.DataFrame(Evaluation, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "Evaluation.to_csv('csvNEO4J/Nodos/evaluation.csv', index=False)   \n",
    "FactEva = pd.DataFrame(FactEva, columns=['fact', 'evaluation']).drop_duplicates()\n",
    "FactEva.to_csv('csvNEO4J/Relaciones/factEva.csv', index=False)\n",
    "FactEvaT = pd.DataFrame(FactEvaT, columns=['fact', 'evaluation']).drop_duplicates()\n",
    "FactEvaT.to_csv('csvNEO4J/Relaciones/factEvaT.csv', index=False)\n",
    "\n",
    "\n",
    "Exprement = pd.DataFrame(Exprement, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "Exprement.to_csv('csvNEO4J/Nodos/exprement.csv', index=False)   \n",
    "FactExp = pd.DataFrame(FactExp, columns=['fact', 'exprement']).drop_duplicates()\n",
    "FactExp.to_csv('csvNEO4J/Relaciones/factExp.csv', index=False)\n",
    "FactExpT = pd.DataFrame(FactExpT, columns=['fact', 'exprement']).drop_duplicates()\n",
    "FactExpT.to_csv('csvNEO4J/Relaciones/factExpT.csv', index=False)\n",
    "\n",
    "Group = pd.DataFrame(Group, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "Group.to_csv('csvNEO4J/Nodos/group.csv', index=False)   \n",
    "FactGro = pd.DataFrame(FactGro, columns=['fact', 'group']).drop_duplicates()\n",
    "FactGro.to_csv('csvNEO4J/Relaciones/factGro.csv', index=False)\n",
    "FactGroT = pd.DataFrame(FactGroT, columns=['fact', 'group']).drop_duplicates()\n",
    "FactGroT.to_csv('csvNEO4J/Relaciones/factGroT.csv', index=False)\n",
    "\n",
    "Method = pd.DataFrame(Method, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "Method.to_csv('csvNEO4J/Nodos/method.csv', index=False)   \n",
    "FactMet = pd.DataFrame(FactMet, columns=['fact', 'method']).drop_duplicates()\n",
    "FactMet.to_csv('csvNEO4J/Relaciones/factMet.csv', index=False)\n",
    "FactMetT = pd.DataFrame(FactMetT, columns=['fact', 'method']).drop_duplicates()\n",
    "FactMetT.to_csv('csvNEO4J/Relaciones/factMetT.csv', index=False)\n",
    "\n",
    "Person = pd.DataFrame(Person, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "Person.to_csv('csvNEO4J/Nodos/person.csv', index=False)   \n",
    "FactPer = pd.DataFrame(FactPer, columns=['fact', 'person']).drop_duplicates()\n",
    "FactPer.to_csv('csvNEO4J/Relaciones/factPer.csv', index=False)\n",
    "FactPerT = pd.DataFrame(FactPerT, columns=['fact', 'person']).drop_duplicates()\n",
    "FactPerT.to_csv('csvNEO4J/Relaciones/factPert.csv', index=False)\n",
    "\n",
    "\n",
    "ResearchField = pd.DataFrame(ResearchField, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "ResearchField.to_csv('csvNEO4J/Nodos/researchField.csv', index=False)   \n",
    "FactRes = pd.DataFrame(FactRes, columns=['fact', 'researchField']).drop_duplicates()\n",
    "FactRes.to_csv('csvNEO4J/Relaciones/factRes.csv', index=False)\n",
    "FactResT = pd.DataFrame(FactResT, columns=['fact', 'researchField']).drop_duplicates()\n",
    "FactResT.to_csv('csvNEO4J/Relaciones/factResT.csv', index=False)\n",
    "\n",
    "Technology = pd.DataFrame(Technology, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "Technology.to_csv('csvNEO4J/Nodos/technology.csv', index=False)   \n",
    "FactTec = pd.DataFrame(FactTec, columns=['fact', 'technology']).drop_duplicates()\n",
    "FactTec.to_csv('csvNEO4J/Relaciones/factTec.csv', index=False)\n",
    "FactTecT = pd.DataFrame(FactTecT, columns=['fact', 'technology']).drop_duplicates()\n",
    "FactTecT.to_csv('csvNEO4J/Relaciones/factTecT.csv', index=False)\n",
    "\n",
    "Tool = pd.DataFrame(Tool, columns=['identifier', 'uri','label']).drop_duplicates()\n",
    "Tool.to_csv('csvNEO4J/Nodos/tool.csv', index=False)   \n",
    "FactToo = pd.DataFrame(FactToo, columns=['fact', 'tool']).drop_duplicates()\n",
    "FactToo.to_csv('csvNEO4J/Relaciones/factToo.csv', index=False)\n",
    "FactTooT = pd.DataFrame(FactTooT, columns=['fact', 'tool']).drop_duplicates()\n",
    "FactTooT.to_csv('csvNEO4J/Relaciones/factTooT.csv', index=False)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a27ac40d",
   "metadata": {},
   "source": [
    "Technology"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb85625",
   "metadata": {},
   "source": [
    "Chunk"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4e922a",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
