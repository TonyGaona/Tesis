{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ded78222-2527-44ba-8393-dd920da6b6f5",
   "metadata": {},
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "import math\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import configparser\n",
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "import time"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6ff71f86-9764-47da-b903-9a330b3d393e",
   "metadata": {},
   "source": [
    "Lectura de variables clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9314bb92-3a36-487e-b0cc-f444e6d00b4c",
   "metadata": {},
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"variables.ini\")   \n",
    "geminiKey = config['DEFAULT']['geminiKey']"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "310348fa-4b7f-4bc5-ba94-9171e4fc1975",
   "metadata": {},
   "source": [
    "Modelo Seleccionado (Gemini Pro 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f642117-8317-4992-94e1-2b3737ab0684",
   "metadata": {},
   "source": [
    "def limpiezaDocumento(document):\n",
    "    document = document.replace(\" ´\", \"\")\n",
    "    document = unicodedata.normalize('NFKD', document).encode('ascii', 'ignore').decode('utf-8')\n",
    "    document = re.sub(r'\\s+', ' ', document)  \n",
    "    return document\n",
    "    \n",
    "def entities_LLM(api_key,document, model_name=\"gemini-1.5-pro\", temperature=0, top_p=0.95, top_k=40, max_output_tokens=1024):\n",
    "    \n",
    "    \n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # Create the model\n",
    "    generation_config = {\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": top_k,\n",
    "        \"max_output_tokens\": max_output_tokens,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    }\n",
    "    \n",
    "    model = genai.GenerativeModel(\n",
    "      model_name=model_name,\n",
    "      generation_config=generation_config,\n",
    "    )\n",
    "    \n",
    "    chat_session = model.start_chat(\n",
    "      history=[\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"parts\": [\n",
    "              \"\"\"\n",
    "            You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph only return that information about artifial intelligence.\n",
    "            Your task is to identify the entities and relations specified in the user prompt from a given text and produce the output in JSON format.\n",
    "            This output should be a list of JSON objects, with each object always containing the following keys:\n",
    "    \n",
    "            •⁠  ⁠\"head\": The text of the extracted entity, which must match one of the types specified in the user prompt.\n",
    "            •⁠  ⁠\"head_type\": The type of the extracted head entity, selected from the specified list of types.\n",
    "            •⁠  ⁠\"relation\": The type of relation between the \"head\" and the \"tail,\" chosen from the list of allowed relations.\n",
    "            •⁠  ⁠\"tail\": The text of the entity representing the tail of the relation.\n",
    "            •⁠  ⁠\"tail_type\": The type of the tail entity, also selected from the provided list of types.\n",
    "    \n",
    "            Extract as many entities and relationships as possible.\n",
    "    \n",
    "            Entity Consistency: Ensure consistency in entity representation. If an entity, like \"John Doe,\" appears multiple times in the text under different names or pronouns (e.g., \"Joe,\" \"he\"), use always the name. \n",
    "    \n",
    "            Important Notes:\n",
    "            •⁠  ⁠Do not add any extra explanations or text.\n",
    "            •⁠  ⁠If no one relation can be optained only return NO\n",
    "            \n",
    "    \n",
    "            allowed_nodes = [\"Person\", \"Organization\", \"Location\", \"Method\", \"ResearchField\",\"Technology\",\"Metric\",\"DataSet\",\"Group\",\"Exprement\",\"Evaluation\",\"Tool\",\"Algoritm\"]\n",
    "            allowed_relations = [\"Accuracy\",\"Advantage\",\"Allow\",\"Applied\",\"Analyzed\",\"based_on\",\"Belongs\",\"Better_than\",\"Capable\",\"Compared\",\"Contains\",\"Used\",\"Describe\",\"Developed\",\"Disadvantage\",\"Evaluated\",\"Goal\",\"Implemented\",\"Includes\",\"Interacts\",\"Located\",\"Metric_value\",\"Participants\",\"Produces\",\"Property\",\"Estudied\",\"Uses\"]\n",
    "            \n",
    "            examples = [\n",
    "                {\n",
    "                    \"head\": \"SVM\",\n",
    "                    \"head_type\": \"Method\",\n",
    "                    \"relation\": \"Accuracy\",\n",
    "                    \"tail\": \"98\",\n",
    "                    \"tail_type\": \"Metric\",\n",
    "                },\n",
    "                {\n",
    "                    \"head\": \"IA\",\n",
    "                    \"head_type\": \"Technology\",\n",
    "                    \"relation\": \"Used\",\n",
    "                    \"tail\": \"classical automation of control\",\n",
    "                    \"tail_type\": \"ResearchField\",\n",
    "                }\n",
    "            ]\n",
    "            Document:\n",
    "              \"\"\"\n",
    "          ],\n",
    "        },\n",
    "      ]\n",
    "    )\n",
    "    response = chat_session.send_message(document)\n",
    "    return response   \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30ba93b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df = pd.read_csv(\"dfEntre30y250.csv\")\n",
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "169c15ff",
   "metadata": {},
   "source": [
    "## Solo ejecutar si se pierde la linea\n",
    "\n",
    "cValidos = 0\n",
    "cFallidos = 0\n",
    "cTotal = 0\n",
    "triples = []\n",
    "pTime = []\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57f19819",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Iteración de bloques de 1000\n",
    "for x in range(5000,5751):\n",
    "    try:\n",
    "        i = df.iloc[x]\n",
    "        cTotal = cTotal + 1\n",
    "        \n",
    "        ## Inicio de tiempo\n",
    "        start_time = time.time()\n",
    "        ## Llamado al modelo\n",
    "        response = entities_LLM(geminiKey,limpiezaDocumento(i.content)) \n",
    "        ## Fin de tiempo\n",
    "        end_time = time.time()\n",
    "        \n",
    "        ## Calculo del tiempo con 4 decimales \n",
    "        processing_time = round(end_time - start_time, 4)\n",
    "\n",
    "        ## Guardar con id y tiempo\n",
    "        pTime.append([x,i.id,processing_time])\n",
    "        \n",
    "        ## Fila ejecutada\n",
    "        print(x,i.id, end=\" \")\n",
    "        \n",
    "        ## Se transforma la salida a json\n",
    "        data = json.loads(response.text)\n",
    "        \n",
    "        ## Se itera por la salida y se guarda cada elemento \n",
    "        for item in data:\n",
    "            triples.append([i.id,i.eid,i.content,i.vector,i.page_number,i.split_id,i.word_count,item['head'],item['head_type'],item['relation'],item['tail'],item['tail_type']])\n",
    "        cValidos = cValidos + 1\n",
    "        print(\"1\")\n",
    "        time.sleep(1)   \n",
    "        \n",
    "    except (json.decoder.JSONDecodeError, TypeError, ValueError, KeyError) as e:\n",
    "        cFallidos = cFallidos + 1\n",
    "        print(\"0\")\n",
    "        \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "277491e4",
   "metadata": {},
   "source": [
    "print(\"Total de documentos con respuesta : \",cValidos)\n",
    "print(\"Total de documentos sin respuesta : \",cFallidos)\n",
    "print(\"Total de documentos               : \",cTotal)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30f76f16",
   "metadata": {},
   "source": [
    "tiempo = pd.DataFrame(pTime)\n",
    "tiempo.columns = ['numero', 'id','tiempo']\n",
    "tiempo = tiempo.drop_duplicates('id')\n",
    "\n",
    "horas = int(round(tiempo['tiempo'].sum()/60/60,10)) \n",
    "minutos = int((round(tiempo['tiempo'].sum()/60/60,10) - horas) * 60)\n",
    "promedio = round(tiempo['tiempo'].sum()/len(tiempo), 2)\n",
    "\n",
    "print(f\"Tiempo Total                      :{horas} horas y {minutos} minutos\")\n",
    "print(f\"Tiempo Promedio                   :{promedio} segundos\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2488e41",
   "metadata": {},
   "source": [
    "T = pd.DataFrame(triples)\n",
    "T"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbc875f5",
   "metadata": {},
   "source": [
    "T.to_csv(\"E_T3kE.csv\", index=False, encoding=\"utf-8\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c980c44f-da4a-4eed-8db7-67dc46634925",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
